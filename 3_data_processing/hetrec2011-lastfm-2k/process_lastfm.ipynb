{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repro processing lastfm2k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   userID  artistID  weight\n",
       "0       2        51   13883\n",
       "1       2        52   11690\n",
       "2       2        53   11351\n",
       "3       2        54   10300\n",
       "4       2        55    8983\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read LFM2k ratings provided by GroupLens: https://grouplens.org/datasets/hetrec-2011/\n",
    "ratings = pd.read_csv('original_data/user_artists.dat', sep='\\t',)\n",
    "print(ratings.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ratings: 92834\n",
       "Users: 1892\n",
       "Items: 17632\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Â print dataset statistics\n",
    "print(f'Ratings: {len(ratings)}')\n",
    "print(f'Users: {len(ratings[\"userID\"].unique())}')\n",
    "print(f'Items: {len(ratings[\"artistID\"].unique())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply core-5 filtering to interactions\n",
    "\n",
    "def core_k_filtering(interactions, k):\n",
    "    \"\"\"\n",
    "    Perform Core5 filtering on a user-item-rating DataFrame.\n",
    "    Ensures that every user and item has at least 5 interactions.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        user_counts = interactions['userID'].value_counts()\n",
    "        item_counts = interactions['artistID'].value_counts()\n",
    "        \n",
    "        valid_users = user_counts[user_counts >= 5].index\n",
    "        valid_items = item_counts[item_counts >= 5].index\n",
    "        \n",
    "        core_k = interactions[interactions['userID'].isin(valid_users) & interactions['artistID'].isin(valid_items)]\n",
    "        \n",
    "        if len(core_k) == len(interactions):\n",
    "            break\n",
    "        \n",
    "        interactions = core_k\n",
    "\n",
    "    return core_k\n",
    "\n",
    "ratings_core5 = core_k_filtering(ratings, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ratings: 71355\n",
       "Users: 1859\n",
       "Items: 2823\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print stats of the core-5 dataset\n",
    "print(f'Ratings: {len(ratings_core5)}')\n",
    "print(f'Users: {len(ratings_core5[\"userID\"].unique())}')\n",
    "print(f'Items: {len(ratings_core5[\"artistID\"].unique())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          id  ...                                         pictureURL\n",
       "0          1  ...    http://userserve-ak.last.fm/serve/252/10808.jpg\n",
       "1          2  ...  http://userserve-ak.last.fm/serve/252/3052066.jpg\n",
       "2          3  ...  http://userserve-ak.last.fm/serve/252/40222717...\n",
       "3          4  ...  http://userserve-ak.last.fm/serve/252/54697835...\n",
       "4          5  ...  http://userserve-ak.last.fm/serve/252/14789013...\n",
       "...      ...  ...                                                ...\n",
       "17627  18741  ...  http://userserve-ak.last.fm/serve/252/16352971...\n",
       "17628  18742  ...   http://userserve-ak.last.fm/serve/252/207445.jpg\n",
       "17629  18743  ...   http://userserve-ak.last.fm/serve/252/344868.jpg\n",
       "17630  18744  ...  http://userserve-ak.last.fm/serve/252/29297695...\n",
       "17631  18745  ...  http://userserve-ak.last.fm/serve/252/59486303...\n",
       "\n",
       "[17632 rows x 4 columns]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "artist_info = pd.read_csv('original_data/artists.dat', sep='\\t')\n",
    "print(artist_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Len artist name after core5: 2823\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# filter out artists not in the core5\n",
    "artist_info_core5 = artist_info[artist_info['id'].isin(set(ratings_core5['artistID']))]\n",
    "print(f'Len artist name after core5: {len(artist_info_core5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_links = pd.read_csv('lfm2k_song_extended_mapping.tsv', sep='\\t')\n",
    "cover_links = pd.read_csv('lfm2k_covers_extended_mapping.tsv', sep='\\t')\n",
    "texts = pd.read_csv('lfm2k_text.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2825\n",
       "2748\n",
       "12523\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "audio_ids = set(audio_links['artistID'])\n",
    "cover_ids = set(cover_links['artistID'])\n",
    "text_ids = set(texts['artistID'])\n",
    "print(len(audio_ids))\n",
    "print(len(cover_ids))\n",
    "print(len(text_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2820\n",
       "2743\n",
       "2813\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(len(set(artist_info_core5['id']).intersection(audio_ids)))\n",
    "print(len(set(artist_info_core5['id']).intersection(cover_ids)))\n",
    "print(len(set(artist_info_core5['id']).intersection(text_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2731\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compute intersections between all items\n",
    "keep_items = audio_ids.intersection(cover_ids).intersection(text_ids).intersection(set(artist_info_core5['id']))\n",
    "print(len(keep_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ratings: 70030\n",
       "Users: 1859\n",
       "Items: 2731\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "multimodal_ratings = ratings_core5[ratings_core5['artistID'].isin(keep_items)]\n",
    "print(f'Ratings: {len(multimodal_ratings)}')\n",
    "print(f'Users: {len(multimodal_ratings[\"userID\"].unique())}')\n",
    "print(f'Items: {len(multimodal_ratings[\"artistID\"].unique())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need convert each .pkl file learned during the extraction process into an .npy file, stored as np.array from 0 to k-1, where k is the total number of items\n",
    "# Moreover, as required by MMRec, we need to provide .npy files with the same number of items\n",
    "\n",
    "# For this reason, we need to filter out all the items that have no any of the multimodal features. \n",
    "# Note that this has been done only in our setting to perform the experiments, but in your case few modalities might be enough,\n",
    "# so you might need to filter out less items or no items at all.\n",
    "\n",
    "# Moreover, this is needed for the MMRec framework, but if you are using other framework - or you own one - this might be not necessary.\n",
    "# This is also the reason we choose to provide the .pkl dict files, in such a way any user can use them the way they need and want to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "whisper.pkl\n",
       "all-mpnet-base-v2.pkl\n",
       "vit_cls.pkl\n",
       "all-MiniLM-L6-v2.pkl\n",
       "vggish.pkl\n",
       "resnet152.pkl\n",
       "vit_avg.pkl\n",
       "vgg.pkl\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read all the items for which we have all the multimodal features.\n",
    "# This is required by MMRec, but is not mandatory if you focus only on a sinlge modality or a subset of them\n",
    "\n",
    "import pickle as pkl\n",
    "import os \n",
    "import numpy as np\n",
    "\n",
    "item_keys = None\n",
    "\n",
    "for pkl_file in os.listdir('multimodal_features/dict/'):\n",
    "\n",
    "    if '.pkl' in pkl_file:\n",
    "        print(pkl_file)\n",
    "        data_dict = pkl.load(open(f'multimodal_features/dict/{pkl_file}', 'rb'))\n",
    "        data_keys = set()\n",
    "\n",
    "        for x in data_dict.keys():\n",
    "            if isinstance(x, str):\n",
    "                k = x.split('_')[0]\n",
    "                data_keys.add(int(k))\n",
    "            else:\n",
    "                data_keys.add(x)\n",
    "\n",
    "        if item_keys is None:\n",
    "            item_keys = set(data_keys)\n",
    "        else:\n",
    "            item_keys &= set(data_keys)\n",
    "\n",
    "print(len(item_keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multimodal_ratings = multimodal_ratings[multimodal_ratings['artistID'].isin(item_keys)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ratings: 56346\n",
       "Users: 1859\n",
       "Items: 1425\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print the updated statistics\n",
    "print(f'Ratings: {len(multimodal_ratings)}')\n",
    "print(f'Users: {len(multimodal_ratings[\"userID\"].unique())}')\n",
    "print(f'Items: {len(multimodal_ratings[\"artistID\"].unique())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Len training: 44327\n",
       "Len training: 4799\n",
       "Len training: 7219\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# split into train, valid, test - in this case, we use the same format required by MMRec, but any strategy can be applied\n",
    "# to avoid any error in the training of the models, we split into 80-10-10 and ensure that all users and items appear in the training\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def split_data(df, train_ratio=0.8, valid_ratio=0.1, test_ratio=0.1, seed=42):\n",
    "    \"\"\"\n",
    "    Splits a dataset into train, validation, and test sets while ensuring that:\n",
    "    - All users and items appear in the training set.\n",
    "    - Validation and test sets do not introduce new users or items.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    train_list, valid_list, test_list = [], [], []\n",
    "    \n",
    "    for _, user_df in df.groupby(\"userID\"):\n",
    "        user_df = user_df.sample(frac=1, random_state=seed)\n",
    "        \n",
    "        num_interactions = len(user_df)\n",
    "        train_end = int(num_interactions * train_ratio)\n",
    "        valid_end = train_end + int(num_interactions * valid_ratio)\n",
    "        \n",
    "        train_list.append(user_df.iloc[:train_end])\n",
    "        valid_list.append(user_df.iloc[train_end:valid_end])\n",
    "        test_list.append(user_df.iloc[valid_end:])\n",
    "    \n",
    "    train_df = pd.concat(train_list).reset_index(drop=True)\n",
    "    valid_df = pd.concat(valid_list).reset_index(drop=True)\n",
    "    test_df = pd.concat(test_list).reset_index(drop=True)\n",
    "    \n",
    "    # Ensure valid & test sets contain only users & items from training\n",
    "    train_users, train_items = set(train_df['userID']), set(train_df['artistID'])\n",
    "    \n",
    "    valid_df = valid_df[valid_df['userID'].isin(train_users) & valid_df['artistID'].isin(train_items)].reset_index(drop=True)\n",
    "    test_df = test_df[test_df['userID'].isin(train_users) & test_df['artistID'].isin(train_items)].reset_index(drop=True)\n",
    "    \n",
    "    return train_df, valid_df, test_df\n",
    "\n",
    "# split data into train, valid, test\n",
    "train, valid, test = split_data(multimodal_ratings)\n",
    "\n",
    "print(f'Len training: {len(train)}')\n",
    "print(f'Len training: {len(valid)}')\n",
    "print(f'Len training: {len(test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>artistID</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>95</td>\n",
       "      <td>1363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>98</td>\n",
       "      <td>1332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>8983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "      <td>3301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>1471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8127</th>\n",
       "      <td>2099</td>\n",
       "      <td>1943</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8128</th>\n",
       "      <td>2099</td>\n",
       "      <td>2605</td>\n",
       "      <td>397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8129</th>\n",
       "      <td>2100</td>\n",
       "      <td>1281</td>\n",
       "      <td>573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8130</th>\n",
       "      <td>2100</td>\n",
       "      <td>3806</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8131</th>\n",
       "      <td>2100</td>\n",
       "      <td>1109</td>\n",
       "      <td>1333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65545 rows Ã 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      userID  artistID  weight\n",
       "0          2        95    1363\n",
       "1          2        98    1332\n",
       "2          2        55    8983\n",
       "3          2        67    3301\n",
       "4          2        90    1471\n",
       "...      ...       ...     ...\n",
       "8127    2099      1943     410\n",
       "8128    2099      2605     397\n",
       "8129    2100      1281     573\n",
       "8130    2100      3806     389\n",
       "8131    2100      1109    1333\n",
       "\n",
       "[65545 rows x 3 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_data = pd.concat([train, valid, test])\n",
    "split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data = pd.concat([train, valid, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# format data into MMRec format\n",
    "# MMRec requires a single .inter file, with a column named 'x_label' that can assume 3 possible values:\n",
    "# - 0: the interaction is in the training set\n",
    "# - 1: the interaction is in the validation set\n",
    "# - 2: the interaction is in the test set\n",
    "train['x_label'] = 0\n",
    "valid['x_label'] = 1\n",
    "test['x_label'] = 2\n",
    "\n",
    "# now, we concat the three dataframe to save the unique .inter file required by MMRec\n",
    "split_data = pd.concat([train, valid, test])\n",
    "\n",
    "# conisder all the interactions as positive\n",
    "split_data['rating'] = 1\n",
    "\n",
    "# remove weight column\n",
    "split_data = split_data[['userID', 'artistID', 'rating', 'x_label']]\n",
    "\n",
    "# rename columns\n",
    "split_data.columns = ['userID', 'itemID', 'rating', 'x_label']\n",
    "\n",
    "# we save this dataset with the original IDs\n",
    "split_data.to_csv('processed_data/lfm2k_og_ids.inter', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to remap both user and item IDs from 0 to n-1\n",
    "\n",
    "map_users = {user_id: i for i, user_id in enumerate(split_data['userID'].unique())}\n",
    "map_items = {item_id: i for i, item_id in enumerate(split_data['itemID'].unique())}\n",
    "\n",
    "inverse_map_item = {i: item_id for item_id, i in map_items.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "def average_grouped_arrays(data_dict):\n",
    "    \"\"\"\n",
    "    Averages all NumPy arrays that share the same prefix in their keys.\n",
    "\n",
    "    Args:\n",
    "        data_dict (dict): A dictionary where keys are strings like '6347_1', '6347_2', \n",
    "                          and values are NumPy arrays.\n",
    "\n",
    "    Returns:\n",
    "        dict: A new dictionary where keys are prefixes (e.g., '6347') and values are \n",
    "              the averaged NumPy arrays.\n",
    "    \"\"\"\n",
    "    grouped_arrays = defaultdict(list)\n",
    "\n",
    "    # Group arrays by their prefix\n",
    "    for key, array in data_dict.items():\n",
    "        if isinstance(key, str):\n",
    "            prefix = int(key.split('_')[0])  # Extract prefix before '_'\n",
    "            grouped_arrays[prefix].append(array)\n",
    "        else:\n",
    "            grouped_arrays[key].append(array)\n",
    "\n",
    "    # Compute the average for each prefix group\n",
    "    averaged_dict = {prefix: np.mean(arrays, axis=0) for prefix, arrays in grouped_arrays.items()}\n",
    "\n",
    "    return averaged_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "whisper\n",
       "2364\n",
       "all-mpnet-base-v2\n",
       "12523\n",
       "vit_cls\n",
       "2314\n",
       "all-MiniLM-L6-v2\n",
       "12523\n",
       "vggish\n",
       "2364\n",
       "resnet152\n",
       "2314\n",
       "vit_avg\n",
       "2314\n",
       "vgg\n",
       "2314\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for each dict of embedding:\n",
    "# 1. get the items that must be kept\n",
    "# 2. compute the centroid related to the same artists\n",
    "# 3. map with the new IDs\n",
    "# 4. store them as np.array\n",
    "\n",
    "for pkl_file in os.listdir('multimodal_features/dict/'):\n",
    "\n",
    "    if '.pkl' in pkl_file:\n",
    "\n",
    "        name_mod = pkl_file.split('.')[0]\n",
    "        print(name_mod)\n",
    "\n",
    "        emb_list = []\n",
    "        \n",
    "        data_dict = pkl.load(open(f'multimodal_features/dict/{pkl_file}', 'rb'))\n",
    "        avg_data_dict = average_grouped_arrays(data_dict)\n",
    "\n",
    "        print(len(avg_data_dict))\n",
    "\n",
    "        for index in range(len(inverse_map_item)):\n",
    "            old_id = inverse_map_item[index]\n",
    "            emb = avg_data_dict[old_id]\n",
    "            emb_list.append(emb)\n",
    "        \n",
    "        emb_array = np.array(emb_list)\n",
    "        np.save(open(f'multimodal_features/mmrec_npy/{name_mod}.npy', 'wb'), emb_array)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data['userID'] = split_data['userID'].map(map_users)\n",
    "split_data['itemID'] = split_data['itemID'].map(map_items)\n",
    "\n",
    "split_data.to_csv('processed_data/lfm2k.inter', sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "whisper.pkl\n",
       "all-mpnet-base-v2.pkl\n",
       "vit_cls.pkl\n",
       "all-MiniLM-L6-v2.pkl\n",
       "vggish.pkl\n",
       "resnet152.pkl\n",
       "vit_avg.pkl\n",
       "vgg.pkl\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# just to be sure that numpy library version mismatch should affect the readability of our embeddings, \n",
    "# we save the multimodal features as json files as well\n",
    "\n",
    "import pickle as pkl\n",
    "import os \n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "item_keys = None\n",
    "\n",
    "for pkl_file in os.listdir('multimodal_features/dict/'):\n",
    "\n",
    "    if '.pkl' in pkl_file:\n",
    "        print(pkl_file)\n",
    "        data_dict = pkl.load(open(f'multimodal_features/dict/{pkl_file}', 'rb'))\n",
    "        \n",
    "        data_dict_serializable = {key: value.tolist() for key, value in data_dict.items()}\n",
    "        with open(f'multimodal_features/json/{pkl_file.split(\".pkl\")[0]}.json', 'w') as f:\n",
    "            json.dump(data_dict_serializable, f, indent=4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
