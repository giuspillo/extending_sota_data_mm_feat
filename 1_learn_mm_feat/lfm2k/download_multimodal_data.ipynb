{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to install the pytube package and the ffmpeg package, as these are the two packages used to download the multimodal features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytube in /Users/giuse/opt/miniconda3/lib/python3.9/site-packages (15.0.0)\n",
      "Collecting ffmpeg\n",
      "  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n",
      "Building wheels for collected packages: ffmpeg\n",
      "  Building wheel for ffmpeg (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6084 sha256=035b68abc325c0dd85276361f303348b09cc0d5a84ca4770345d70f7b1422ce0\n",
      "  Stored in directory: /Users/giuse/Library/Caches/pip/wheels/1d/57/24/4eff6a03a9ea0e647568e8a5a0546cdf957e3cf005372c0245\n",
      "Successfully built ffmpeg\n",
      "Installing collected packages: ffmpeg\n",
      "Successfully installed ffmpeg-1.4\n"
     ]
    }
   ],
   "source": [
    "!pip install pytube\n",
    "!pip install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import yt_dlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we read the dataframe that contains the cover urls of the albums associated to each artist, so we can download it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cover_links = pd.read_csv('lfm2k_covers_extended_mapping.tsv', sep='\\t')\n",
    "artist_covers = cover_links.groupby(\"artistID\")[\"link_cover\"].apply(list).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this function, we download the image and store it in the correct format <item_id>_<counter> (several images can be associated to the same item)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image(url, item_id, counter):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        with open(f\"_covers/{item_id}_{counter}.jpg\", \"wb\") as file:\n",
    "            file.write(response.content)\n",
    "            print('done!')\n",
    "            time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate over the grouped DataFrame to get each image link associated to each artist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n",
      "done!\n",
      "done!\n",
      "done!\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "for item_id, url_list in artist_covers.items():\n",
    "\n",
    "    # we save the covers as artistid_1, artistid_2, etc.\n",
    "    for counter, cover_url in enumerate(url_list):\n",
    "        download_image(cover_url, item_id, counter+1)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we read the dataframe that contains the urls of the songs associated to each artist, so we can download it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_links = pd.read_csv('lfm2k_song_extended_mapping.tsv', sep='\\t')\n",
    "artist_video = video_links.groupby(\"artistID\")[\"link_song\"].apply(list).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this function, we download the song and store it in the correct format <item_id>_<counter> (several songs can be associated to the same item)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_youtube_audio(url, item_id, counter):\n",
    "\n",
    "    ydl_opts = {\n",
    "        'ffmpeg_location': '/opt/homebrew/bin/ffmpeg',\n",
    "        'format': 'bestaudio/best',\n",
    "        'postprocessors': [{\n",
    "            'key': 'FFmpegExtractAudio',\n",
    "            'preferredcodec': 'mp3',\n",
    "            'preferredquality': '192',\n",
    "        }],\n",
    "        'outtmpl': f'_songs/{item_id}_{counter}.mp3'\n",
    "    }\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        ydl.download([url])\n",
    "        print('done!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate over the grouped DataFrame to get each song link associated to each artist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "for item_id, url_video in artist_video.items():\n",
    "\n",
    "    # we save the songs as artistid_1, artistid_2, etc.\n",
    "    for counter, song_url in enumerate(url_list):\n",
    "        download_youtube_audio(song_url, item_id, counter+1)\n",
    "        break\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
